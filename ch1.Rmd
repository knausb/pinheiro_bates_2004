---
title: "Chapter 1"
author: "Brian J. Knaus"
date: "7/14/2017"
output: 
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(fig.height = 4)
knitr::opts_chunk$set(fig.width = 4)
```

## 1.1 A simple example of random effects


In order to introduce the concept of random effects Pinheiro and Bates use an example that tests railroad rails.
The example comes with teh package `lme4`.


```{r}
library(nlme)
head(Rail)
class(Rail)
plot(Rail)
```


We see that the data are in a `data.frame`-like object that appears tabular.
The `plot` method reproduces the figure from the book and shows that our dataset consists of 6 rails that have each been tested 3 times.


Our first attempt to characterize the data ignores any grouping information.
Mathematically it is expressed as follows.


$$
y_{ij} = \beta + \epsilon_{ij},\\
i = 1, ..., M, \\
j = 1, ..., n_{i}. (1.1)
$$


Here $M$ iterates over rails, $j$ iterates over observations for each rail, $n_{i}$ is the number of observations for each rail, $y$ is our response (travel), $\beta$ is tha parameter we'd like to infer and  $\epsilon$ is the normally distributed error term.
In R we express this with a model formula.


```{r}
fm1Rail.lm <- lm(travel ~ 1, data = Rail)
summary(fm1Rail.lm)
```


The model only asks to inferr the intercept (indicates by `~ 1`).
This is analagous to taking a simple mean: `r mean(Rail$travel)`.
The variation we observe around this mean is 23.65 which, as pointed out in the book, is substantial.


We build a slightly more complex model by adding 'rail effects' as a 'fixed effect.'
Mathematically we express this as follows.


$$
y_{ij} = \beta_{i} + \epsilon_{ij},\\
i = 1, ..., M, \\
j = 1, ..., n_{i}. (1.2)
$$


Note that our parameter $\beta$ now has a counter.

The model formula for fitting this model in R is below.


```{r}
fm2Rail.lm <- lm(travel ~ Rail - 1, data = Rail)
summary(fm2Rail.lm)
```


We now have a mean for each rail.
These values can be compared to the plot above.


A random effects model would be as follows.


$$
y_{ij} = \beta + b_{i} + \epsilon_{ij}, (1.4)\\
$$


Here, $\beta$ is the mean travel time across the population of rails and $b_{i}$ is a random variable representing the deviation from the population mean of the mean travel time for the $i$th rail.
We now have two random variables.


$$
b_{i} \sim N(0, \sigma^{2}_{b}), \epsilon \sim N(0, \sigma^{2}). (1.5)
$$


### 1.1.1 Fitting the random-effects model with lme


```{r}
fm1Rail.lme <- lme(travel ~ 1, data = Rail, random = ~ 1 | Rail)
summary(fm1Rail.lme)
```



```{r}
fm1Rail.lmeML <- update(fm1Rail.lme, method = "ML")
summary(fm1Rail.lmeML)
```


### 1.1.2 Assessing the fitted model


```{r}
plot(fm1Rail.lme)
intervals(fm1Rail.lme)
anova(fm1Rail.lme)
```




## 1.2 A randomized block design


A randomized block experiment has two classification factors: an experimental factor where we'll use 'fixed effects' and blocking factor where we'll use 'random effects.'
In the ergoStool example there are four types of stool that we wish to make inferences about, so we use fixed effects.
There are 9 subjects that measured the stools represent a sample from a population which we would like to make inferences about so we use random effects to model them.


```{r}
plot(ergoStool)
plot.design(ergoStool)
```



## 1.2 Choosing contrasts for fixed-effects terms


Our model for our randomized block design can be expressed mathematically.

$$
y_{ij} = \beta_{j} + b_{i} + \epsilon_{ij}, i = 1, ..., 9, j = 1, ..., 4\\
b_{i} \sim N(0,\sigma^{2}_{b}), \epsilon \sim N(0, \sigma^{2})(1.6)
$$


Note that equation 1.6 differs from equation 1.4 in that we now have a counter for our parameter ($\beta$) to count the different subjects.




```{r}
#options( contrasts = c(factor = "contr.treatment", ordered = "contr.poly"))
options( contrasts = c(factor = "contr.helmert", ordered = "contr.poly"))
contrasts(ergoStool$Type)
```


```{r}
ergoStool1 <- ergoStool[ ergoStool$Subject == "1", ]
model.matrix( effort ~ Type, ergoStool1)
```



```{r}
fm1Stool <- lme(effort ~ Type, data = ergoStool, random = ~ 1 | Subject)
summary(fm1Stool)
anova(fm1Stool)
```



```{r}
options( contrasts = c(factor = "contr.treatment", ordered = "contr.poly"))
#options( contrasts = c(factor = "contr.helmert", ordered = "contr.poly"))
contrasts(ergoStool$Type)
fm2Stool <- lme(effort ~ Type, data = ergoStool, random = ~ 1 | Subject)
summary(fm2Stool)
anova(fm2Stool)
```


```{r}
model.matrix( effort ~ Type - 1, ergoStool1 )
fm3Stool <- lme(effort ~ Type, data = ergoStool, random = ~ 1 | Subject)
summary(fm3Stool)
anova(fm3Stool)
```


### 1.2.2 Examining the model


```{r, fig.width=6}
intervals(fm1Stool)
plot(fm1Stool, form = resid(., type = "p") ~ fitted(.) | Subject, abline = 0)
```


## 1.3 Mixed-effects models for replicated, blocked designs


```{r, fig.width = 6}
plot(Machines)
```


```{r, fig.width=6}
attach(Machines)
interaction.plot(Machine, Worker, score, las = 1)
detach()
```


### Fitting random interaction terms


$$
y_{ijk} = \beta_{j} + b_{i} + \epsilon_{ijk}, i = 1, ..., 6, j = 1, ..., 3, k = 1, ..., 3,\\
b_{i} ~\sim N(o, \sigma^{2}_{b}), \epsilon_{ijk} \sim N(0, \sigma^{2}) (1.7)
$$


This differs from equation 1.6 in that the response ($y$) and the error ($\epsilon$) include an additional counter ($k$) to iterate over the replicates.


```{r}
fm1Machine <- lme(score ~ Machine, data = Machines, random = ~ 1 | Worker)
summary(fm1Machine)
```


$$
y_{ijk} = \beta_{j} + b_{i} + b_{ij} + \epsilon_{ijk},\\
i = 1, ..., 6,\\
j = 1, ..., 3,\\
k = 1, ..., 3,\\
b_{i} \sim N(0, \sigma^{}_{1}),\\
b_{ij} \sim N(0, \sigma^{2}_{2}),\\
\epsilon_{ijk} \sim N(0, \sigma^{2}).
$$


This model includes a random effect for Worker as well as a random effect for Machine within Worker.
It can be expressed in R as follows.


```{r}
fm2Machine <- update(fm1Machine, random = ~ 1 | Worker/Machine )
summary(fm2Machine)
anova(fm1Machine, fm2Machine)
```


### 1.3.2 Unbalanced data



```{r}
# Omit 10 of 54 values.
MachinesUnbal <- Machines[-c(2,3,6,8,9,12,19,20,27,33), ]
table(MachinesUnbal$Machine, MachinesUnbal$Worker)
fm1MachinesU <- lme( score ~ Machine, data = MachinesUnbal, random = ~ 1 | Worker/Machine)
summary(fm1MachinesU)
intervals(fm1MachinesU)
```


Note that you need some level of replication or else this will not work.
Make sure to check the intervals to check this phenomenon.


### 1.3.3





## 1.4 An analysis of covariance model



## 1.5 Models for nested classification factors




## 1.6 A split-plot experiment



